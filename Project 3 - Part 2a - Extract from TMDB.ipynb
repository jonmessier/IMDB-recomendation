{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69872f4c",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Jon Messier\n",
    "\n",
    "2/20/2023\n",
    "\n",
    "---\n",
    "\n",
    "**Business Problem**\n",
    "\n",
    "For this project, you have been hired to produce a MySQL database on Movies from a subset of IMDB's publicly available dataset. Ultimately, you will use this database to analyze what makes a movie successful and will provide recommendations to the stakeholder on how to make a successful movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a09930",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Part 1\n",
    "\n",
    "For Part 1 of the project, you will be creating your project repository, loading the official IMDB data for the requested tables, filtering out unnecessary data, and saving the filtered tables as gzip-compressed csv files (\".csv.gz\") in your repository.\n",
    "\n",
    "**Getting Started Tips:**\n",
    "\n",
    "- Please make sure to read the following lesson [\"Getting Started - Project 3\"](https://login.codingdojo.com/m/376/12528/88061) for additional tips and directions!\n",
    "    \n",
    "  **The Data**\n",
    "\n",
    "- IMDB Provides Several Files with varied information for Movies, TV Shows, Made for TV Movies, etc.\n",
    "-   Overview/Data Dictionary: https://www.imdb.com/interfaces/\n",
    "- Downloads page: https://datasets.imdbws.com/\n",
    "\n",
    "- From their previous research, they realized they want to focus on the following files:\n",
    " -  title.basics.tsv.gz\n",
    " - title.ratings.tsv.gz\n",
    " - title.akas.tsv.gz\n",
    "\n",
    "\n",
    "**Specifications**\n",
    "\n",
    "Your stakeholder only wants you to include information for movies based on the following specifications:\n",
    "\n",
    "-    Exclude any movie with missing values for genre or runtime\n",
    "-    Include only full-length movies (titleType = \"movie\").\n",
    "-    Include only fictional movies (not from documentary genre)\n",
    "-   Include only movies that were released 2000 - 2021 (include 2000 and 2021)\n",
    "-    Include only movies that were released in the United States\n",
    "\n",
    "\n",
    "**Deliverable**\n",
    "\n",
    "After filtering out movies that do not meet the stakeholder's specifications:\n",
    "\n",
    "-    Before saving, run a final .info() for each of the dataframes to show a summary of how many movies remain and the datatypes of each feature\n",
    "-    Save each file to a compressed csv file \"Data/\" folder inside your repository.\n",
    "-    Commit your changes to your repository in GitHub desktop and Publish repository / Push Changes.\n",
    "-    Submit the link to your repository\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3b910",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Class/Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768c7fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be1844",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basics_url = \"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "ratings_url = 'https://datasets.imdbws.com/title.ratings.tsv.gz'\n",
    "akas_url = 'https://datasets.imdbws.com/title.akas.tsv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8481c1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data Inspection and cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac3080",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Aka's\n",
    "- [x]  Replace \"\\N\" with np.nan\n",
    "- [x] Keep only US movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb9d4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_akas = pd.read_csv(akas_url, sep='\\t', low_memory=False)\n",
    "df_akas.info()\n",
    "df_akas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ed94b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#replace \\N with np.nan\n",
    "df_akas = df_akas.replace({'\\\\N':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ce51a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Keep only US movies\n",
    "df_akas=df_akas.loc[df_akas['region']==\"US\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b42b8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Basics\n",
    "- [x]   Replace \"\\N\" with np.nan\n",
    "- [x]   Eliminate movies that are null for runtimeMinutes\n",
    "- [x] Eliminate movies that are null for genre\n",
    "- [x] keep only titleType==Movie\n",
    "- [x] keep startYear 2000-2022\n",
    "- [x]  Eliminate movies that include \"Documentary\" in genre (see tip below)\n",
    "- [x]  Keep only US movies (Use AKAs table, see \"Filtering one dataframe based on another\" section below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cb0d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_basics = pd.read_csv(basics_url, sep='\\t', low_memory=False)\n",
    "df_basics.info()\n",
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03267d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#replace \\N with np.nan\n",
    "df_basics = df_basics.replace({'\\\\N':np.nan})\n",
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977470c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop null runtimes\n",
    "df_basics = df_basics.dropna(axis=0, subset='runtimeMinutes')\n",
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a5f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop null genre\n",
    "df_basics = df_basics.dropna(axis=0,subset = 'genres')\n",
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5b29d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#keep titletype=movie\n",
    "df_basics=df_basics[df_basics['titleType']=='movie']\n",
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89139765",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f17e48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop null startYears\n",
    "df_basics = df_basics.dropna(axis=0,subset = 'startYear')\n",
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6513b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert year to an int\n",
    "df_basics['startYear']=df_basics['startYear'].astype('int')\n",
    "\n",
    "#Keep only the movies between 2000-2022\n",
    "df_basics=df_basics.loc[(df_basics[\"startYear\"]>= 2000) \n",
    "                        & (df_basics[\"startYear\"]<= 2022)]\n",
    "df_basics['startYear'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40985806",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclude movies that are included in the documentary category.\n",
    "is_documentary = df_basics['genres'].str.contains('documentary',case=False)\n",
    "df_basics = df_basics[~is_documentary]\n",
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24133d63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Filter the basics table down to only include the US by using the filter ...\n",
    "#Akas dataframe\n",
    "keepers =df_basics['tconst'].isin(df_akas['titleId'])\n",
    "df_basics = df_basics[keepers]\n",
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533be861",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ratings\n",
    "\n",
    "- [x]   Replace \"\\N\" with np.nan\n",
    "- [x]   Keep only US movies (Use AKAs table, see \"Filtering one dataframe based on another\" section below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f67bf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(ratings_url, sep='\\t', low_memory=False)\n",
    "df_ratings.info()\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5c4c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#replace \\N with np.nan\n",
    "df_ratings = df_ratings.replace({'\\\\N':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3056b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Filter the ratings table down to only include the US by using the filter ...\n",
    "#Akas dataframe\n",
    "keepers =df_ratings['tconst'].isin(df_akas['titleId'])\n",
    "df_ratings = df_ratings[keepers]\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67fb53",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Data File storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248deef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# example making new folder with os\n",
    "import os\n",
    "os.makedirs('Data/',exist_ok=True) \n",
    "# Confirm folder created\n",
    "os.listdir(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984e146",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Save current dataframe to file.\n",
    "df_basics.to_csv(\"Data/title_basics.csv.gz\",compression='gzip',index=False)\n",
    "df_ratings.to_csv(\"Data/title_akas.csv.gz\",compression='gzip',index=False)\n",
    "df_akas.to_csv(\"Data/title_ratings.csv.gz\",compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8a2b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open saved file and preview again\n",
    "df_basics = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory = False)\n",
    "df_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26edad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open saved file and preview again\n",
    "df_akas = pd.read_csv(\"Data/title_akas.csv.gz\", low_memory = False)\n",
    "df_akas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2136eb5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open saved file and preview again\n",
    "df_ratings = pd.read_csv(\"Data/title_ratings.csv.gz\", low_memory = False)\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552c742",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## File .info() summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936c209",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d52f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c0b13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_akas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa56ab",
   "metadata": {},
   "source": [
    "# Part 2a.\n",
    "### Your Stakeholder Wants More Data!\n",
    "\n",
    "-   After investigating the preview of your data from Part 1, your stakeholder realized that there is no financial information included in the IMDB data (e.g. budget or revenue).\n",
    " -    This will be a major roadblock when attempting to analyze which movies are successful and must be addressed before you will be able to determine which movies are successful.\n",
    "\n",
    "-  Your stakeholder identified The Movie Database (TMDB) as a great source of financial data (https://www.themoviedb.org/). Thankfully, TMDB offers a free API for programmatic access to their data!\n",
    "\n",
    "-  Your stakeholder wants you to extract the budget, revenue, and MPAA Rating (G/PG/PG-13/R), which is also called \"Certification\".\n",
    "\n",
    "-   **Note: this process can take a long time and may need to run overnight.**\n",
    "\n",
    "---\n",
    "\n",
    "### Specifications - Financial Data\n",
    "\n",
    "- Your stakeholder would like you to extract and save the results for movies that meet all of the criteria established in part 1 of the project (You should already have a filtered dataframe saved from part one as a csv.gz file)\n",
    "\n",
    "-  As a proof-of-concept, they requested you perform a test extraction of movies that started in 2000 or 2001\n",
    "\n",
    "-   Each year should be saved as a separate .csv.gz file\n",
    "\n",
    "**Hint: Use the two custom functions from the lessons (Intro to TMDB API, and Efficient TMDB API Calls). Be sure to define these functions prior to calling them in your code!**\n",
    "\n",
    "-  One function will add the certification (MPGG Rating) to movie.info\n",
    "-  The other function will help you append/extend a JSON file with Python\n",
    "\n",
    "**Confirm Your API Function works.**\n",
    "\n",
    "In order to ensure your function for extracting movie data from TMDB is working, test your function on these 2 movie ids: tt0848228 (\"The Avengers\") and tt0332280 (\"The Notebook\"). Make sure that your function runs without error and that it returns the correct movie's data for both test ids.\n",
    "\n",
    "**Hint: Ideally you can organize the code segments from the previous lesson to create an outer and inner loop, but if you get stuck, you can complete 1 year at a time.**\n",
    "\n",
    "-  Once you have retrieved and saved the final results to 2 separate .csv.gz files, move on to a new Exploratory Data Analysis notebook to explore the following questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ec203",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Class Import, API connection\n",
    "Import key clases, connect to TMDB api and local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01c07d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tmdbsimple as tmdb\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import os, time, json\n",
    "\n",
    "with open('/Users/jonme/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2a7a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273e29b",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ac687",
   "metadata": {},
   "source": [
    "### `get_movie_with_rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    \n",
    "    info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    \n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1']=='US':\n",
    "            info['certification']=c['certification']\n",
    "    return info     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c416e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test get_movie... function with Avengers \"tt0848228\"\n",
    "test = get_movie_with_rating(\"tt0848228\") \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9770a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### `write_json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ec4cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be715ef5",
   "metadata": {},
   "source": [
    "## Load existing data\n",
    "Load in the Title Basics data\n",
    "\n",
    "You need to read in the filtered dataframe you created based on the specification of project 3 Part 1.\n",
    "\n",
    "You will be filtering out the movies for each year inside the loop, so we will need this loaded and ready to be filtered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ef19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for DATA folder\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9951a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('Data/title_basics.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df5af7",
   "metadata": {},
   "source": [
    "**Create Required Lists for the Loop**\n",
    "\n",
    "Define a list of the Years to Extract from the API\n",
    "\n",
    "We have data from 2000 - 2020 available. If we just want results for the first two years, we will create a YEARS_TO_GET list. This will control our outer loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = list(range(2000,2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3f948",
   "metadata": {},
   "source": [
    "**Define an errors list**\n",
    "\n",
    "We will want to be able to save the id's and error messages for any movie that causes an error. To do so, we will want to create an empty errors list before our loops that we can append to later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6af861",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caa9e2",
   "metadata": {},
   "source": [
    "### Write JSON data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1dd641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    print(f'{JSON_FILE} status {file_exists}')\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "    \n",
    "        #Saving new year as the current df\n",
    "        df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "        # saving movie ids to list\n",
    "        movie_ids = df['tconst'].copy()\n",
    "    \n",
    "        # Load existing data from json into a dataframe called \"previous_df\"\n",
    "        previous_df = pd.read_json(JSON_FILE)\n",
    "    \n",
    "        # filter out any ids that are already in the JSON_FILE\n",
    "        movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    \n",
    "        #Get index and movie id from list\n",
    "        # INNER Loop\n",
    "        for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "            try:\n",
    "                # Retrieve then data for the movie id\n",
    "                temp = get_movie_with_rating(movie_id)  \n",
    "                # Append/extend results to existing file using a pre-made function\n",
    "                write_json(temp,JSON_FILE)\n",
    "                # Short 20 ms sleep to prevent overwhelming server\n",
    "                time.sleep(0.02)\n",
    "            \n",
    "            except Exception as e:\n",
    "                errors.append([movie_id, e])\n",
    "    \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\",\n",
    "                         compression=\"gzip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "135px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
